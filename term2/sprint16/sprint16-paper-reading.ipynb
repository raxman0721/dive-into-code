{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sprint16課題　論文読解入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の論文を読み問題に答えてください。CNNを使った物体検出（Object Detection）の代表的な研究です。  \n",
    "[8]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99  \n",
    "https://arxiv.org/pdf/1506.01497.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**問題**  \n",
    "\n",
    "- 物体検出の分野にはどういった手法が存在したか。\n",
    "- Fasterとあるが、どういった仕組みで高速化したのか。\n",
    "- One-Stageの手法とTwo-Stageの手法はどう違うのか。 \n",
    "- RPNとは何か。\n",
    "- RoIプーリングとは何か。\n",
    "- Anchorのサイズはどうするのが適切か。\n",
    "- 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。\n",
    "- （アドバンス）Faster R-CNNよりも新しい物体検出の論文では、Faster R-CNNがどう引用されているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 物体検出の分野にはどういった手法が存在したか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Recent advances in object detection are driven by\n",
    "the success of region proposal methods (e.g., [4])\n",
    "and region-based convolutional neural networks (RCNNs) [5]. Although region-based CNNs were computationally expensive as originally developed in [5],\n",
    "their cost has been drastically reduced thanks to sharing convolutions across proposals [1], [2]. The latest\n",
    "incarnation, Fast R-CNN [2], achieves near real-time\n",
    "rates using very deep networks [3], when ignoring the\n",
    "time spent on region proposals. Now, proposals are the\n",
    "test-time computational bottleneck in state-of-the-art\n",
    "detection systems.\n",
    "Region proposal methods typically rely on inexpensive features and economical inference schemes.\n",
    "Selective Search [4], one of the most popular methods, greedily merges superpixels based on engineered\n",
    "low-level features. Yet when compared to efficient\n",
    "detection networks [2], Selective Search is an order of\n",
    "magnitude slower, at 2 seconds per image in a CPU\n",
    "implementation. EdgeBoxes [6] currently provides the\n",
    "best tradeoff between proposal quality and speed,\n",
    "at 0.2 seconds per image. Nevertheless, the region\n",
    "proposal step still consumes as much running time\n",
    "as the detection network.\n",
    "\n",
    "- R-CNN\n",
    "- Selective Search\n",
    "- SPP-net (スケーリングの手法)\n",
    "- Fast R-CNN\n",
    "- EdgeBoxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fasterとあるが、どういった仕組みで高速化したのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lang": "en"
   },
   "source": [
    "CNNを使用した"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">we introduce novel “anchor” boxes\n",
    "that serve as references at multiple scales and aspect\n",
    "ratios. Our scheme can be thought of as a pyramid\n",
    "of regression references (Figure 1, c), which avoids\n",
    "enumerating images or filters of multiple scales or\n",
    "aspect ratios. This model performs well when trained\n",
    "and tested using single-scale images and thus benefits\n",
    "running speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "アンカーを設定することで色んなサイズ、大量の特徴領域を提案せずに１つの領域を提案してくれる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# One-Stageの手法とTwo-Stageの手法はどう違うのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">The first module is a deep fully convolutional network that proposes regions, and the second module is the Fast R-CNN detector [2] that uses the proposed regions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "one-stageは領域を提案するためのCNNで、Two-stageは提案された領域を使うCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RPNとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "lang": "en"
   },
   "source": [
    ">. An RPN is a fully convolutional\n",
    "network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to\n",
    "generate high-quality region proposals, which are used by Fast R-CNN for detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">An RPN is a fully convolutional\n",
    "network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to\n",
    "generate high-quality region proposals, which are used by Fast R-CNN for detection.\n",
    "\n",
    "物体領域の推測と、オブジェクト性の精度（その領域に対するオブジェクトの割合的なもの）を算出する。  \n",
    "ここで物体領域候補を選び出して、fast R-cnnに渡してあげる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RoIプーリングとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">The RoI pooling layer uses max pooling to convert the\n",
    "features inside any valid region of interest into a small feature map with a fixed spatial extent of H × W (e.g., 7 × 7),\n",
    "where H and W are layer hyper-parameters that are independent of any particular RoI. In this paper, an RoI is a\n",
    "rectangular window into a conv feature map. Each RoI is\n",
    "defined by a four-tuple (r, c, h, w) that specifies its top-left\n",
    "corner (r, c) and its height and width (h, w).\n",
    "\n",
    "抽出された領域に対して、様々なサイズやスケール感があるのでそこを統一して、固定サイズに変換することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Anchorのサイズはどうするのが適切か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">An anchor is centered at the sliding window\n",
    "in question, and is associated with a scale and aspect\n",
    "ratio (Figure 3, left). By default we use 3 scales and\n",
    "3 aspect ratios, yielding k = 9 anchors at each sliding\n",
    "position. For a convolutional feature map of a size\n",
    "W × H (typically ∼2,400), there are W Hk anchors in\n",
    "total.\n",
    "\n",
    "対象のスケールやアスペクト比を考慮する必要がある。\n",
    "論文では3つのサイズとアスペクト比を使用している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "PASCAL VOC\n",
    "Selective Serch(SS)とRPN+VGGの手法にて比較を行った。  \n",
    "RPNを使用したモデルの方がmAPが上昇した。  \n",
    "速度も早くなっている。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "ja"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ja",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
