{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sprint11課題 深層学習スクラッチディープニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。  \n",
    "\n",
    "前回作成した3層のニューラルネットワークを、クラスを活用することで、任意の構成に拡張しやすいコードに書き換えていきます。  \n",
    "その上で、活性化関数や初期値、最適化手法について発展的なものを扱えるようにしていきます。  \n",
    "\n",
    "このようなスクラッチを行うことで、今後各種フレームワークを利用していくにあたり、内部の動きが想像できることを目指します。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新たなニューラルネットワーク分類器のクラスを作成する  \n",
    "Sprint9で作成したものとは別に、ニューラルネットワーク分類器のクラス*ScratchDeepNeuralNetrowkClassifier*を作成してください。  \n",
    "## 層などのクラス化 \n",
    "**コーディング**  \n",
    "クラスにまとめて行くことで、構成を変更しやすい実装にしていきます。  \n",
    "\n",
    "**手を加える箇所**\n",
    "\n",
    "- 層の数\n",
    "- 層の種類（今後は畳み込み層など他のタイプの層が登場する）\n",
    "- 活性化関数の種類\n",
    "- 重みやバイアスの初期化方法\n",
    "- 最適化手法  \n",
    "\n",
    "そのために、全結合層、各種活性化関数、重みやバイアスの初期化、最適化手法それぞれのクラスを作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】全結合層のクラス化\n",
    "**コーディング**\n",
    "\n",
    "全結合層のクラスの雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。  \n",
    "\n",
    "重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。  \n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。  \n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself = self.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。  \n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### インポートと以前までのスプリントのクラスを呼び込む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:27:36.098210Z",
     "start_time": "2019-06-29T12:27:32.751760Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pyprind\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:27:37.447891Z",
     "start_time": "2019-06-29T12:27:37.438940Z"
    }
   },
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10):\n",
    "        self.batch_size = batch_size\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:27:38.779355Z",
     "start_time": "2019-06-29T12:27:38.770567Z"
    }
   },
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数pre_nodesからnodesへの全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    nodes : int\n",
    "      層のノード数\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    group : 'FC'\n",
    "      layerの種類\n",
    "    \"\"\"\n",
    "    def __init__(self, nodes):\n",
    "        self.nodes = nodes\n",
    "        self.group = 'FC'\n",
    "        \n",
    "    def initialize(self, pre_nodes, summary, init_type, optimizer, sigma=1e-2, lr=1e-2):\n",
    "        \"\"\"\n",
    "        重み、バイアスを初期化して出力数を渡してあげる\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim :次の形のtuple, (入力チャンネル,高さ,横幅)\n",
    "            入力サイズ\n",
    "        initializer: class\n",
    "            initializerのクラス\n",
    "        optimizer: class\n",
    "            optimizerのクラス\n",
    "        lr : float(1e-2)\n",
    "            optimizerに渡す学習率\n",
    "        sigma : float(1e-2)\n",
    "            Simpleinitializerを選んだ時のパラメータ\n",
    "        \"\"\"\n",
    "        \n",
    "        #初期値を設定する。\n",
    "        initializer = Initializer(init_type, pre_nodes, sigma)\n",
    "        self.W = initializer.W(pre_nodes, self.nodes)\n",
    "        self.B = initializer.B(self.nodes)\n",
    "        \n",
    "        if summary:\n",
    "            print(self.group,'layer shape={}, param={}'.format(self.W.shape,pre_nodes*self.nodes+self.nodes))\n",
    "\n",
    "        #optimizerを設定する。\n",
    "        self.optimizer = optimizer(lr)\n",
    "        \n",
    "        return self.nodes\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, pre_nodes)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, nodes)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        self.Z = X.copy()\n",
    "        A = X @ self.W + self.B\n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, nodes)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, pre_nodes)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dB = dA\n",
    "        self.dW = self.Z.T @ dA\n",
    "        dZ = dA @ self.W.T\n",
    "        # 重みを更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】初期化方法のクラス化  \n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。  \n",
    "雛形に必要なコードを書き加えていってください。  \n",
    "標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:27:40.593765Z",
     "start_time": "2019-06-29T12:27:40.587846Z"
    }
   },
   "outputs": [],
   "source": [
    "class Initializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期値設定\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, init_type, pre_nodes, sigma):\n",
    "        if init_type == 'simple':\n",
    "            self.sigma = sigma\n",
    "        elif init_type == 'Xavier':\n",
    "            self.sigma = 1 / np.sqrt(pre_nodes)\n",
    "        elif init_type == 'He':\n",
    "            self.sigma = np.sqrt(2 / pre_nodes)\n",
    "\n",
    "    def W(self,*args):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : int\n",
    "          ノード数や、チャンネル数等必要なサイズを入力\n",
    "        Returns\n",
    "        ----------\n",
    "        W :次の形のndarray, shape (args)\n",
    "            重み\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.standard_normal(size=args)\n",
    "        return W\n",
    "    def B(self, *args):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : int\n",
    "          ノード数等を入力。入力した形の必要なサイズを入力\n",
    "        Returns\n",
    "        ----------\n",
    "        B :次の形のndarray, shape (args)\n",
    "            バイアス\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.standard_normal(size=args)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】最適化手法のクラス化  \n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。  \n",
    "バックワードのときにself = self.optimizer.update(self)のように更新できるようにします。  \n",
    "こちらも雛形を用意しましたので、必要なコードを書き加えていってください。  \n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:27:44.849538Z",
     "start_time": "2019-06-29T12:27:44.844763Z"
    }
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        \n",
    "        layer.W -= self.lr * (layer.dW / layer.dB.shape[0])\n",
    "        layer.B -= self.lr * np.mean(layer.dB, axis=0)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】活性化関数のクラス化\n",
    "活性化関数もクラス化を行なってください。  \n",
    "\n",
    "上記サンプルコード3ではソフトマックス関数のバックプロパゲーションに交差エントロピー誤差の計算も含む実装を想定しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:27:49.227383Z",
     "start_time": "2019-06-29T12:27:49.222290Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \"\"\"\n",
    "    　シグモイド関数の活性化関数\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "        self.group = 'activation'\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワードプロパゲーションのときのメソッド\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 全結合後の行列 shapeはどんな形でも大丈夫\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 活性化後の行列　元のshapeを保持\n",
    "        \"\"\"\n",
    "        self.Z = 1 / (1 + np.exp(-A))\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 全結合後の行列  shapeはどんな形でも大丈夫\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 活性化後の行列　元のshapeを保持\n",
    "        \"\"\"\n",
    "        dA = dZ * (1 - self.Z) * self.Z\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:27:50.136774Z",
     "start_time": "2019-06-29T12:27:50.130883Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \"\"\"\n",
    "    ハイパボリックタンジェント関数\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "        self.group = 'activation'\n",
    "\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワードプロパゲーションのときのメソッド\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 全結合後の行列 shapeはどんな形でも大丈夫\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 活性化後の行列 元のshapeを保持\n",
    "        \"\"\"\n",
    "        self.Z = np.tanh(A)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 全結合後の行列 shapeはどんな形でも大丈夫\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 活性化後の行列　元のshapeを保持\n",
    "        \"\"\"\n",
    "        dA = dZ * (1 - self.Z ** 2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:27:53.150252Z",
     "start_time": "2019-06-29T12:27:53.143148Z"
    }
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \"\"\"\n",
    "    ソフトマックス関数の活性化関数\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "        self.entropy = None # バッチ単位でのエントロピー\n",
    "        self.group = 'activation'\n",
    "        \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワードプロパゲーションのときのメソッド\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 全結合後の行列 shape(batch_size, pre_nodes)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 活性化後の行列　shape(batch_size,  pre_nodes)\n",
    "        \"\"\"\n",
    "        c = np.max(A,axis=1,keepdims=True)\n",
    "        A = np.exp(A-c)\n",
    "        self.Z = A / np.sum(A, axis=1, keepdims=True)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, Y):\n",
    "        \"\"\"\n",
    "        バックワードと交差エントロピーを計算\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 全結合後の行列 shape(batch_size, pre_nodes)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 活性化後の行列　shape(batch_size,  pre_nodes)\n",
    "        \"\"\"\n",
    "        #勾配はこっち\n",
    "        dA = self.Z - Y\n",
    "        return dA\n",
    "    \n",
    "    def loss(self, Y):\n",
    "        entropy = -np.sum(Y * np.log(self.Z + 1e-5), axis=1) #サンプル毎のエントロピー(batch_size,)\n",
    "        entropy = entropy.sum() / len(entropy)  # スカラー\n",
    "        return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】ReLUクラスの作成\n",
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装します。  \n",
    "ReLUは以下の数式です。\n",
    "$$\n",
    "% <![CDATA[\n",
    "f(x) = ReLU(x) = \\begin{cases}\n",
    "x  & \\text{if $x>0$,}\\\\\n",
    "0 & \\text{if $x\\leqq0$.}\n",
    "\\end{cases} %]]>\n",
    "$$\n",
    "\n",
    "x : ある特徴量。スカラー  \n",
    "\n",
    "実装上はnp.maximumを使い配列に対してまとめて計算が可能です。  \n",
    "\n",
    "一方、バックプロパゲーションのための x に関する $f(x)$ の微分は以下のようになります。  \n",
    "$$\n",
    "% <![CDATA[\n",
    "\\frac{\\partial f(x)}{\\partial x} = \\begin{cases}\n",
    "1  & \\text{if $x>0$,}\\\\\n",
    "0 & \\text{if $x\\leqq0$.}\n",
    "\\end{cases} %]]>\n",
    "$$  \n",
    "数学的には微分可能ではないですが、 x=0 のとき 0 とすることで対応しています。   \n",
    "フォワード時の x の正負により、勾配を逆伝播するかどうかが決まるということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:27:56.149111Z",
     "start_time": "2019-06-29T12:27:56.143300Z"
    }
   },
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    \"\"\"\n",
    "    ReLU関数の活性化関数\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.group = 'activation'\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワードプロパゲーションのときのメソッド\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 全結合後の行列 shapeはどんな形でも大丈夫\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Z : 活性化後の行列　元のshapeを保持\n",
    "        \"\"\"\n",
    "        self.mask = (A <= 0)\n",
    "        Z = A.copy()\n",
    "        Z[self.mask] = 0\n",
    "        return  Z\n",
    "\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 全結合後の行列shapeはどんな形でも大丈夫\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        dA : 活性化後の行列　元のshapeを保持\n",
    "        \"\"\"\n",
    "        dZ[self.mask] = 0\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。  \n",
    "しかし、一般的に良い初期値の取り方が知られています。  \n",
    "\n",
    "シグモイド関数やハイパボリックタンジェント関数のときはXavierの初期値（またはGlorotの初期値）、ReLUのときはHeの初期値が使われます。  \n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成します。  \n",
    "\n",
    "それぞれの初期化方法における σ は次の式で求められます。  \n",
    "\n",
    "### 「Xavierの初期値」  \n",
    "\n",
    "$$\n",
    "\\sigma = \\frac{1}{\\sqrt{n}}\n",
    "$$\n",
    "n : 前の層のノード数  \n",
    "\n",
    "**[論文](https://arxiv.org/pdf/1502.01852.pdf)**\n",
    "\n",
    "### 「Heの初期値」\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{2}{n}}\n",
    "$$\n",
    "\n",
    "n : 前の層のノード数\n",
    "\n",
    "**[論文](https://arxiv.org/pdf/1502.01852.pdf)**\n",
    "\n",
    "### 上記2クラスともInitializerクラスに導入済み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】最適化手法\n",
    "**コーディング**  \n",
    "\n",
    "学習率は学習の良し悪しにとって重要なハイパーパラメータであり、これを学習過程で変化させていく方法が現在では一般的です。  \n",
    "様々な手法が提案されていますが、今回はその中でも基本的な、AdaGradを実装します。  \n",
    "まず、これまで使ってきたSGDを確認します。\n",
    "$$\n",
    "W_i^{\\prime} = W_i - \\alpha E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "B_i^{\\prime} = B_i - \\alpha E(\\frac{\\partial L}{\\partial B_i})\n",
    "$$\n",
    "\n",
    "$\n",
    "α  : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\\\\\n",
    "\\frac{∂L}{∂W_i} : W_i に関する損失 L の勾配\\\\\n",
    "\\frac{∂L}{∂B_i} : B_i に関する損失 L の勾配\\\\\n",
    "E() : ミニバッチ方向にベクトルの平均を計算\\\\\n",
    "$\n",
    "\n",
    "続いて、AdaGradです。バイアスの数式は省略しますが、重みと同様のことをします。  \n",
    "\n",
    "更新された分だけその重みに対する学習率を徐々に下げていきます。イテレーションごとの勾配の二乗和H を保存しておき、その分だけ学習率を小さくします。  \n",
    "学習率は重み一つひとつに対して異なることになります。  \n",
    "\n",
    "$$ \n",
    "H_i^{\\prime}  = H_i+E(\\frac{\\partial L}{\\partial W_i})×E(\\frac{\\partial L}{\\partial W_i})\\\\\n",
    "W_i^{\\prime} = W_i - \\alpha \\frac{1}{\\sqrt{H_i^{\\prime} }} E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "$$ \n",
    "\n",
    "\n",
    "$\n",
    "H_i  : i層目に関して、前のイテレーションまでの勾配の二乗和（初期値は0）\\\\\n",
    "H′_i : 更新した H_i\\\\\n",
    "$\n",
    "\n",
    "**AdaGrad**クラスを作成し、上記の数式にもとづいて実装してください。\n",
    "\n",
    "**[論文](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:28:02.842526Z",
     "start_time": "2019-06-29T12:28:02.836622Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    AdaGrad\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.H_w = 0 #最初は0\n",
    "        self.H_b = 0\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        dW_mean = layer.dW / layer.dB.shape[0] #行列\n",
    "        dB_mean = np.mean(layer.dB, axis=0)\n",
    "        #重みの更新\n",
    "        self.H_w += dW_mean * dW_mean # Hを更新\n",
    "        layer.W -= self.lr * dW_mean / (np.sqrt(self.H_w) + 1e-7)\n",
    "        \n",
    "        self.H_b +=  dB_mean * dB_mean        \n",
    "        layer.B -= self.lr * dB_mean / (np.sqrt(self.H_b) + 1e-7)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最後は全てをまとめたクラスを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T02:17:24.102930Z",
     "start_time": "2019-07-16T02:17:24.069618Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier:\n",
    "    \"\"\"\n",
    "    ディープなニューラルネットワーク分類器\n",
    "    層を増やすことが出来る。\n",
    "    バッチをランダムで抽出する。\n",
    "    エポック毎にバッチを取り直すことも可能。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size : int　(30)\n",
    "        バッチサイズ\n",
    "    n_epoch : int (100)\n",
    "        エポック数\n",
    "    e_threshold : float(1e-2)\n",
    "        エポック途中終了の為のエントロピーの閾値\n",
    "    n_iter : int(1000)\n",
    "        1エポック辺りのイテレーション数\n",
    "    repeat_batch_process : bool(True)\n",
    "        Trueの場合１エポック毎にバッチをランダムに取り直す。\n",
    "    restore_extraction:bool(True)\n",
    "        学習するバッチをランダム抽出する際に復元か、非復元か選ぶ。基本は復元(ブートストラップ)\n",
    "    seed : int(0)\n",
    "        ランダムシード\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    loss : shape(n_epoch, n_iter)\n",
    "        1バッチごとのエントロピー\n",
    "    layers : list\n",
    "        layerのリスト\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size=30,\n",
    "        n_epochs=100,\n",
    "        e_threshold=1e-2,\n",
    "        n_iter=1000,\n",
    "        repeat_batch_process=True,\n",
    "        restore_extraction=True,\n",
    "        seed=0\n",
    "    ):\n",
    "        self._n_iter = n_iter\n",
    "        self._repeat_batch_process = repeat_batch_process\n",
    "        self._restore_extraction = restore_extraction\n",
    "        self._batch_size = batch_size\n",
    "        self._n_epochs = n_epochs\n",
    "        self._e_threshold = e_threshold  # 誤差の閾値        \n",
    "        self.loss = None\n",
    "        self.epoch_loss_mean = None\n",
    "                            \n",
    "    def sequential(self,*layers):\n",
    "        \"\"\"\n",
    "        layerをつなげるメソッド。\n",
    "        \"\"\"\n",
    "        self.layers = []        \n",
    "        for layer in layers:\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "    def initialize(self, input_dim, summary, init_type, optimizer, sigma=1e-2, lr=1e-2):\n",
    "        \"\"\"\n",
    "        それぞれのlayerの初期化メソッド\n",
    "        活性化層以外の層のinitializeメソッドを使う。\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            if layer.group != 'activation':\n",
    "                input_dim = layer.initialize(input_dim,summary, init_type, optimizer, sigma=sigma, lr=lr)\n",
    "        \n",
    "\n",
    "    def fit(self, X, y ,validation_split=0.1):\n",
    "        \"\"\"\n",
    "        NNを学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, クラス)\n",
    "            学習用データの正解値(one_hot_vectaされた後のもの)\n",
    "        validation_split : float\n",
    "            検証用データに使用する割合。        \n",
    "        \"\"\"\n",
    "        \n",
    "        # trainとvalにデータを分ける。        \n",
    "        split_index = int(X.shape[0] * validation_split)\n",
    "        X_train = X[split_index:]\n",
    "        y_train = y[split_index:]\n",
    "        X_val = X[:split_index]\n",
    "        y_val = y[:split_index]\n",
    "        \n",
    "        # yの値をワンホットエンコーディングする。        \n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "        y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "\n",
    "\n",
    "        # repeat_batchしない場合はここでミニバッチ化\n",
    "        if self._repeat_batch_process == False:\n",
    "            train_batch = GetMiniBatch(X_train, y_train_one_hot,\n",
    "                                       batch_size=self._batch_size) \n",
    "        # バッチをランダム取得するためのindexを取得\n",
    "        batch_index = np.random.choice(int(X_train.shape[0] / self._batch_size),\n",
    "                                       self._n_iter,\n",
    "                                       replace=self._restore_extraction)  # n_iterのindex\n",
    "        self.train_loss = []  # 1エポックの平均のlossの入れ物\n",
    "        self.val_loss = []  # 1エポックの平均のlossの入れ物\n",
    "        self.train_acc = []\n",
    "        self.val_acc = []\n",
    "\n",
    "        # 学習開始\n",
    "        for epoch in tqdm(range(self._n_epochs)):\n",
    "            if self._repeat_batch_process:\n",
    "                train_batch = GetMiniBatch(\n",
    "                    X_train, y_train_one_hot, batch_size=self._batch_size)  # バッチに分ける。\n",
    "            for i, index in enumerate(batch_index):\n",
    "                X_batch, y_batch = train_batch[index][0].copy(\n",
    "                ), train_batch[index][1].copy()\n",
    "                # フォワードプロパゲーション\n",
    "                for layer_index in range(len(self.layers)):\n",
    "                    X_batch = self.layers[layer_index].forward(X_batch)\n",
    "                # バックプロパゲーション\n",
    "                for layer_index in range(1, len(self.layers) + 1):\n",
    "                    y_batch = self.layers[-layer_index].backward(y_batch)\n",
    "            \n",
    "            # エポックごとにlossとaccを計算\n",
    "            tr_pred = self.predict(X_train)\n",
    "            tr_loss = self.layers[-1].loss(y_train_one_hot)\n",
    "            val_pred = self.predict(X_val)\n",
    "            val_loss = self.layers[-1].loss(y_val_one_hot)\n",
    "            tr_acc = np.sum(y_train == tr_pred) / X_train.shape[0]\n",
    "            val_acc = np.sum(y_val == val_pred) / X_val.shape[0]\n",
    "            self.train_loss.append(tr_loss)\n",
    "            self.val_loss.append(val_loss)\n",
    "            self.train_acc.append(tr_acc)\n",
    "            self.val_acc.append(val_acc)\n",
    "            print('{}エポック目のloss= {:.5f}'.format(epoch,tr_loss))\n",
    "            # 誤差が閾値以下になったらエポック終了\n",
    "            if tr_loss < self._e_threshold:\n",
    "                print('lossが{:.3f}より低いよ！'.format(self._e_threshold))\n",
    "                break\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        NNで予測する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, チャンネル数,高さ,幅)\n",
    "            学習用データの特徴量        \n",
    "        \"\"\"\n",
    "\n",
    "        # フォワードプロパゲーション\n",
    "        out = X.copy()\n",
    "        for layer in range(len(self.layers)):\n",
    "            out = self.layers[layer].forward(out)\n",
    "\n",
    "        return np.argmax(out, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前回のデータセットを使用して試してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:28:15.805841Z",
     "start_time": "2019-06-29T12:28:15.211308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "X_train = x_train.reshape(-1, 784)\n",
    "X_test = x_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(y_train.shape) # (60000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:28:18.368598Z",
     "start_time": "2019-06-29T12:28:18.365507Z"
    }
   },
   "outputs": [],
   "source": [
    "dnn = ScratchDeepNeuralNetrowkClassifier(batch_size=32,\n",
    "                                n_epochs=70,\n",
    "                                n_iter=500,\n",
    "                                repeat_batch_process=False,\n",
    "                                restore_extraction=False,\n",
    "                                seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:28:22.149146Z",
     "start_time": "2019-06-29T12:28:22.136831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC layer shape=(784, 128), param=100480\n",
      "FC layer shape=(128, 50), param=6450\n",
      "FC layer shape=(50, 10), param=510\n"
     ]
    }
   ],
   "source": [
    "dnn.sequential(\n",
    "    FC(128),\n",
    "    Relu(),\n",
    "    FC(50), \n",
    "    Relu(),\n",
    "    FC(10), \n",
    "    Softmax()\n",
    ")\n",
    "\n",
    "input_dim = (784)\n",
    "dnn.initialize(input_dim, summary=True, init_type='He', optimizer=AdaGrad, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:29:33.071174Z",
     "start_time": "2019-06-29T12:28:24.525702Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e564043580459eb0e2685e7f592f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=70), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0エポック目のloss= 0.22363\n",
      "1エポック目のloss= 0.18141\n",
      "2エポック目のloss= 0.16015\n",
      "3エポック目のloss= 0.14607\n",
      "4エポック目のloss= 0.13666\n",
      "5エポック目のloss= 0.12939\n",
      "6エポック目のloss= 0.12349\n",
      "7エポック目のloss= 0.11868\n",
      "8エポック目のloss= 0.11445\n",
      "9エポック目のloss= 0.11111\n",
      "10エポック目のloss= 0.10816\n",
      "11エポック目のloss= 0.10566\n",
      "12エポック目のloss= 0.10337\n",
      "13エポック目のloss= 0.10156\n",
      "14エポック目のloss= 0.10002\n",
      "15エポック目のloss= 0.09863\n",
      "16エポック目のloss= 0.09740\n",
      "17エポック目のloss= 0.09639\n",
      "18エポック目のloss= 0.09542\n",
      "19エポック目のloss= 0.09474\n",
      "20エポック目のloss= 0.09399\n",
      "21エポック目のloss= 0.09340\n",
      "22エポック目のloss= 0.09291\n",
      "23エポック目のloss= 0.09248\n",
      "24エポック目のloss= 0.09212\n",
      "25エポック目のloss= 0.09179\n",
      "26エポック目のloss= 0.09146\n",
      "27エポック目のloss= 0.09125\n",
      "28エポック目のloss= 0.09099\n",
      "29エポック目のloss= 0.09078\n",
      "30エポック目のloss= 0.09065\n",
      "31エポック目のloss= 0.09051\n",
      "32エポック目のloss= 0.09039\n",
      "33エポック目のloss= 0.09032\n",
      "34エポック目のloss= 0.09021\n",
      "35エポック目のloss= 0.09018\n",
      "36エポック目のloss= 0.09014\n",
      "37エポック目のloss= 0.09011\n",
      "38エポック目のloss= 0.09011\n",
      "39エポック目のloss= 0.09009\n",
      "40エポック目のloss= 0.09013\n",
      "41エポック目のloss= 0.09016\n",
      "42エポック目のloss= 0.09019\n",
      "43エポック目のloss= 0.09024\n",
      "44エポック目のloss= 0.09028\n",
      "45エポック目のloss= 0.09032\n",
      "46エポック目のloss= 0.09041\n",
      "47エポック目のloss= 0.09046\n",
      "48エポック目のloss= 0.09052\n",
      "49エポック目のloss= 0.09061\n",
      "50エポック目のloss= 0.09067\n",
      "51エポック目のloss= 0.09080\n",
      "52エポック目のloss= 0.09087\n",
      "53エポック目のloss= 0.09098\n",
      "54エポック目のloss= 0.09105\n",
      "55エポック目のloss= 0.09114\n",
      "56エポック目のloss= 0.09122\n",
      "57エポック目のloss= 0.09134\n",
      "58エポック目のloss= 0.09141\n",
      "59エポック目のloss= 0.09152\n",
      "60エポック目のloss= 0.09161\n",
      "61エポック目のloss= 0.09171\n",
      "62エポック目のloss= 0.09181\n",
      "63エポック目のloss= 0.09190\n",
      "64エポック目のloss= 0.09200\n",
      "65エポック目のloss= 0.09208\n",
      "66エポック目のloss= 0.09218\n",
      "67エポック目のloss= 0.09229\n",
      "68エポック目のloss= 0.09236\n",
      "69エポック目のloss= 0.09246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dnn.fit(X_train, y_train,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T12:29:33.498747Z",
     "start_time": "2019-06-29T12:29:33.108933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x131c44dd68>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=np.arange(len(dnn.train_acc)),y=dnn.val_acc)\n",
    "sns.lineplot(x=np.arange(len(dnn.train_acc)),y=dnn.train_acc)\n",
    "plt.show()\n",
    "sns.lineplot(x=np.arange(len(dnn.train_acc)),y=dnn.train_loss)\n",
    "sns.lineplot(x=np.arange(len(dnn.train_acc)),y=dnn.val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まあまあ精度が高いからとりあえずオーケー"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "660.208px",
    "left": "1757.57px",
    "right": "20px",
    "top": "120px",
    "width": "355.764px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
